<!DOCTYPE html>

<html lang="en">



<head>

    <meta charset="UTF-8">

    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>Copy Text Buttons</title>

    <style>

        button {

            margin: 5px;

        }



        body {

            background-color: #f0f0f0;

            /* Light gray background */

            font-family: Arial, sans-serif;

            text-align: center;

        }



        button {

            margin: 10px;

            padding: 10px;

            font-size: 16px;

            background-color: #ddd;

            /* Light gray button background */

            border: 1px solid #aaa;

            /* Dark gray border */

            cursor: pointer;

        }



        button:hover {

            background-color: #ccc;

            /* Slightly darker background on hover */

        }

    </style>

</head>



<body>



    <button onclick="copyText(text1)"">P1(A) KNN</button>

  <button onclick=" copyText(text2)">P1(B) KMeans</button>

    <button onclick="copyText(text3)">P2 Naive Bayes(Gaussian)</button>

    <button onclick="copyText(text4)">P3 OverFitting</button>

    <button onclick="copyText(text5)">P4 Linear Regression</button>

    <button onclick="copyText(text6)">P5 SVC/SVM</button>

    <button onclick="copyText(text7)">P6(A) Kmeans Random Sample Data</button>

    <button onclick="copyText(text8)">P6(B) Kmeans Income & Spending Data</button>

    <button onclick="copyText(text9)">P7 Decision Tree</button>

    <button onclick="copyText(text10)">P8 Agglomerative Clustering/Hierarchical Clustering</button>

    <button onclick="copyText(text11)">Assignment 1 Confusion Matrix Multi Class Classification</button>

    <button onclick="copyText(text12)">Assignment 2 Multi Class Classification Using KNN</button>

    <button onclick="copyText(text13)">Assignment 3 Multi Label Classification</button>

    <button onclick="copyText(text14)">Assignment 4 Income Happiness Linear Regression</button>

    <p id="copiedMsg"></p>

    <script>

        var text1 = `
#import Necessary libraries
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import  accuracy_score
import matplotlib.pyplot as plt

#Load the data

iris = load_iris()

iris.data.shape

#Split the dataset into features and target

X,Y = iris.data,iris.target

#Split the dataset into training and testing set

X_Train,X_Test,Y_Train,Y_Test = train_test_split(X,Y,test_size= 0.33,random_state=99)

#initialize a KNearest Classifier

knn_cls = KNeighborsClassifier(n_neighbors = 4)

#Train the model on the training data

knn_cls.fit(X_Train,Y_Train)

#Make prediction on test data

pred = knn_cls.predict(X_Test)

#Evaluate the model accuracy

acc = accuracy_score(Y_Test,pred)
print("Accuracy :",acc)

# Plotting the scatter graph
plt.scatter(X_Test[:, 0], X_Test[:, 1], c=Y_Test, cmap='viridis')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.show()
`;

        var text2 = `
# Import necessary libraries
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

# Load the Iris dataset
iris = load_iris()

# Split the dataset into features and target
X, Y = iris.data, iris.target

# Initialize KMeans clustering with 3 clusters
Km = KMeans(n_clusters=3, random_state=40)

# Fit KMeans to the data
Km.fit(X)

# Get cluster labels
cluster_labels = Km.labels_

# Plot the clusters
plt.scatter(X[:, 0], X[:, 1], c=cluster_labels, cmap='viridis')
plt.title("Scatter Plot of Iris Dataset using K-Means Clustering\n")
plt.show()
`;

        var text3 = `

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.datasets import load_iris
print("KFMSCIT007 - Dhanraj Chinta")

# Load the Iris dataset
iris = load_iris()
# Extract features (X) and target (y) from the dataset
X = iris.data
y = iris.target

# Split the data into training and testing sets
# X_train, X_test: input data for training and testing
# y_train, y_test: corresponding target labels for training and testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize Gaussian Naive Bayes model
GNB = GaussianNB()

# Train the model using the training data
GNB.fit(X_train, y_train)

# Predict using the trained model on the test data
y_pred = GNB.predict(X_test)

# Predict the species with user input
user_input = [[5.9, 3.0, 5.1, 1.8]]  # Example user input
predicted_index = GNB.predict(user_input)
predicted_species = iris.target_names[predicted_index]
print("Predicted species for user input:", predicted_species)

# Confusion Matrix
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
# Accuracy Score
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy Score:", accuracy)
# Classification Report
print("Classification Report:")
print(classification_report(y_test, y_pred))
`;

        var text4 = `

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Generate synthetic data
np.random.seed(0)
X = np.linspace(0, 5, 100).reshape(-1, 1)
Y = 2 * np.sin(X) + np.random.normal(0, 0.5, size=X.shape)

# Split data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Define a function to fit polynomial regression models of varying degrees
def fit_polynomial(X_train, Y_train, X_test, Y_test, degree):
    poly = PolynomialFeatures(degree=degree)
    X_train_poly = poly.fit_transform(X_train)
    X_test_poly = poly.transform(X_test)

    model = LinearRegression()
    model.fit(X_train_poly, Y_train)

    train_rmse = np.sqrt(mean_squared_error(Y_train, model.predict(X_train_poly)))
    test_rmse = np.sqrt(mean_squared_error(Y_test, model.predict(X_test_poly)))

    return model, train_rmse, test_rmse

# Fit polynomial regression models of varying degrees
degrees = [1, 3, 10]
models = []
train_rmse_values = []
test_rmse_values = []

for degree in degrees:
    model, train_rmse, test_rmse = fit_polynomial(X_train, Y_train, X_test, Y_test, degree)
    models.append(model)
    train_rmse_values.append(train_rmse)
    test_rmse_values.append(test_rmse)

# Plot the results
plt.figure(figsize=(10, 6))
plt.scatter(X_train, Y_train, color='blue', label='Training Data')
plt.scatter(X_test, Y_test, color='green', label='Testing Data')x_values = np.linspace(0, 5, 100).reshape(-1, 1)
for i, model in enumerate(models):
    y_values = model.predict(PolynomialFeatures(degree=degrees[i]).fit_transform(x_values))
    plt.plot(x_values, y_values, label=f'Degree {degrees[i]}')

plt.title('Polynomial Regression with Different Degrees\n')
plt.xlabel('X')
plt.ylabel('Y')
plt.legend()
plt.show()
`;

        var text5 = `

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Load the dataset
data = pd.read_csv("Salary_Data.csv")

# Extract features (Years of Experience) and target (Salary)
x = data['YearsExperience'].values.reshape(-1, 1)
y = data["Salary"].values

# Split the data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=99)

# Initialize and train the Linear Regression model
model = LinearRegression()
model.fit(x_train, y_train)

# Make predictions on the testing set
predictions = model.predict(x_test)

# Calculate R-squared score
r2 = r2_score(y_test, predictions)
print("R-squared Score:", r2)
print("Dhanraj Chinta - KFMSCIT007")

# Plot the actual vs. predicted values
plt.scatter(x_test, y_test, color='blue', label='Actual')
plt.scatter(x_test, predictions, color='red', label='Predicted')
plt.xlabel('Years of Experience')
plt.ylabel('Salary')
plt.title('Linear Regression: Salary Prediction\n')
plt.legend()
plt.show()

`;

        var text6 = `

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.svm import SVC

# Load the iris dataset
data = pd.read_csv('iris.csv')

# Separate features (X) and target (Y)
X = data.iloc[:, :-1].values
Y = data.iloc[:, -1].values

# Split the data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=10)

# Initialize and train the Support Vector Classifier (SVC)
model = SVC()
model.fit(X_train, Y_train)

# Predict the target labels for the test set
Y_pred = model.predict(X_test)

# Calculate evaluation metrics
accuracy = accuracy_score(Y_test, Y_pred)
precision = precision_score(Y_test, Y_pred, average='macro')
recall = recall_score(Y_test, Y_pred, average='macro')
f1 = f1_score(Y_test, Y_pred, average='macro')

print("")
print("---------------------------")
# Print the evaluation metrics
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

`;

        var text7 = `
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# Sample data
data = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.5], [7, 9], [9, 10], [5.5, 8.5]])

# Number of clusters (k)
k = 3

# Applying KMeans clustering
kmeans = KMeans(n_clusters=k, random_state=0)
clusters_labels = kmeans.fit_predict(data)

# Plotting clustered data
plt.scatter(data[:, 0], data[:, 1], c=clusters_labels,label='Data Points')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='*', s=140, c='green', label='Cluster Centers')
plt.xlabel('X Coordinate')
plt.ylabel('Y Coordinate')
plt.title('\nKMeans Clustering (k=' + str(k) + ')')
plt.legend()
plt.show()


`;

        var text8 = `

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# Sample data representing (Income and Spending)
data = pd.DataFrame({'Income': [25000, 50000, 75000, 100000, 125000, 150000, 175000, 200000],
                     'Spending': [15000, 25000, 35000, 45000, 55000, 65000, 75000, 85000]})

# Number of clusters (k)
k = 3

# Applying KMeans clustering
kmeans = KMeans(n_clusters=k, random_state=0)
clusters_labels = kmeans.fit_predict(data)

# Plotting clustered data
plt.scatter(data['Income'], data['Spending'], c=clusters_labels, cmap='viridis', label='Data Points')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='*', s=140, c='green', label='Cluster Centers')
plt.xlabel('Income')
plt.ylabel('Spending')
plt.title('Dhanraj Chinta - KFMSCIT007\nKMeans Clustering (k=' + str(k) + ')')
plt.legend()
plt.show()

`;

    var text9 = `

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

# Load the Iris dataset
data = pd.read_csv('iris.csv')
# Separate features (X) and target (y)
X = data.drop('species', axis=1)
y = data['species']
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the Decision Tree Classifier
model = DecisionTreeClassifier()
model.fit(X_train, y_train)
# Make predictions on the testing set
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

# Print classification report for more evaluation metrics
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Visualize the decision tree
plt.figure(figsize=(12, 8))
plot_tree(model, filled=True, feature_names=X.columns, class_names=y.unique().astype(str))
plt.title("Decision Tree Visualization \n")
plt.show()
    `;

    var text10 =`
import numpy as np
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics import silhouette_score, completeness_score

# Sample dataset
data = np.array([[1, 1], [5, 5], [8, 8], [1, 0], [5, 4], [8, 1]])

# Parameters
n_clusters = 2
linkage = 'ward'  # Method for calculating linkage
# Perform agglomerative clustering
model = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage)
cluster_labels = model.fit_predict(data)

# Calculate silhouette score
silhouette = silhouette_score(data, cluster_labels)
print("Silhouette Score:", silhouette)

# Calculate completeness score if applicable
g = None  # Ground truth labels, if available
if linkage == 'ward' and g is not None:
    completeness = completeness_score(g, cluster_labels)
    print("Completeness Score:", completeness)
else:
    print("Completeness Score is not applicable for the selected linkage method.")

    `;
    var text11 =`
    import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

actual = np.array(['Apple', 'Orange', 'Banana', 'Apple', 'Orange', 'Apple', 'Orange', 'Banana', 'Banana', 'Apple'])
predicted = np.array(['Apple', 'Orange', 'Orange', 'Apple', 'Orange', 'Apple', 'Orange', 'Banana', 'Banana', 'Orange'])

cm = confusion_matrix(actual,predicted)

sns.heatmap(cm,annot=True,fmt='g',xticklabels=['Apple', 'Orange', 'Banana'],yticklabels=['Apple', 'Orange', 'Banana'])
plt.ylabel('Prediction', fontsize=13)
plt.xlabel('Actual', fontsize=13)
plt.title('Confusion Matrix', fontsize=17)
plt.show()

print(classification_report(actual, predicted))
    `;
    var text12 =`
    # Import necessary libraries
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
# Load the Iris dataset
iris = load_iris()
X = iris.data  # Features
y = iris.target  # Target variable (labels)
#Apply Standard Scaler on feature
scaler = StandardScaler()
x_scaled = scaler.fit_transform(x)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=42)

# Initialize the k-NN classifier (with k=3)
knn_classifier = KNeighborsClassifier(n_neighbors=3)

# Train the classifier on the training data
knn_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = knn_classifier.predict(X_test)

#Evaluate the accuracy of the classifier
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')


    `;
    var text13 =`
    from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.multioutput import MultiOutputClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

documents = [
    "This study investigates the impact of diet on health outcomes.",
    "New advancements in medical technology revolutionize healthcare.",
    "A review of recent breakthroughs in cancer treatment research.",
    "The role of genetics in determining susceptibility to diseases.",
    "Understanding the connection between mental health and physical well-being."
]

# Multi-label classification labels
labels = {
    'Healthcare': [1, 0],
    'Medical Research': [0, 1]
}

# Repeat documents and labels to create 100 samples
documents *= 20  # Repeat each document 20 times to get 100 documents

# Repeat labels accordingly
y = [labels['Healthcare'], labels['Healthcare'], labels['Medical Research'],labels ['Medical Research'], [1, 1]] * 20

# Print length to verify (Optional)
print("Number of documents:", len(documents))
print("Number of labels:", len(y))

# Splitting the dataset into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(documents, y, test_size=0.2, random_state=42)

# Vectorizing the text data
tfidf_vectorizer = TfidfVectorizer()nnnn
x_train_tfidf = tfidf_vectorizer.fit_transform(x_train)
x_test_tfidf = tfidf_vectorizer.transform(x_test)

# Multi-output classifier with Naive Bayes
classifier = MultiOutputClassifier(MultinomialNB())

# Training the classifier
classifier.fit(x_train_tfidf, y_train)

# Predictions
predictions = classifier.predict(x_test_tfidf)

    `;
    var text14 =`
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error,accuracy_score

# Load the data
data = pd.read_csv('Form Responses.csv')  # Replace 'responses.csv' with the path to your CSV file
print("Data loaded successfully.")
data.head()

data.dropna(inplace=True)

X = data[['Salary']].values
y = data['Satisfaction'].values

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)

    
    `;
        function copyText(text) {

            navigator.clipboard.writeText(text).then(function () {

                document.getElementById('copiedMsg').innerHTML = "Text Copied"

            }).catch(function (err) {

                console.error('Unable to copy text', err);

            });

        }

    </script>



</body>



</html>
